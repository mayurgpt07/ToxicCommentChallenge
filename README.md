#### Toxic Comments Classification
File Name - NaturalToxicLanguage.py <br />
It is a Natural Language Processing and Classification problem, that involves specifying whether a comment is Toxic, Severe Toxic, Obscene, Threat, Insult and Identity Hate. In the problem, I am using TFIDF algorithm for word embeddings and then Logistic Regression, Support Vector classifier to predict which class a comment belongs to.  
